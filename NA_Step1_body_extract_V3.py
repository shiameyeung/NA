# ä¾èµ– / Dependencies / ä¾å­˜é–¢ä¿‚ï¼špython-docx, pandas, openpyxl, unicodedata, tqdm, spacy, fuzzywuzzy, python-Levenshtein
# å®‰è£… / Install / ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼špip install python-docx pandas openpyxl tqdm spacy fuzzywuzzy python-Levenshtein
# æ¨¡å‹ä¸‹è½½ / Model Download / ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼špython -m spacy download en_core_web_sm
# åŸä½œè€…ï¼šæ¨å¤©ä¹@å…³è¥¿å¤§å­¦ / Author: Shiame Yeung@Kansai University / ä½œæˆè€…ï¼šæ¥Šã€€å¤©æ¥½@é–¢è¥¿å¤§å­¦

import os
import re
import unicodedata
from docx import Document
import pandas as pd
from tqdm import tqdm

# ------------------ ç”¨æˆ·å¯é…ç½® ------------------
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = SCRIPT_DIR  # æ ¹ç›®å½•å°±æ˜¯è„šæœ¬æ‰€åœ¨ä½ç½®
OUTPUT_CSV = os.path.join(SCRIPT_DIR, 'keyword_hit.csv')  # è¾“å‡ºä¸º CSVï¼Œä¸Step2/Step3ä¿æŒä¸€è‡´
# -----------------------------------------------

# å®šä¹‰å…³é”®è¯æ ¹åˆ—è¡¨ / Keyword roots list
KEYWORD_ROOTS = [
    'partner','alliance','collaborat','cooper','cooperat','join','merger','acquisiti',
    'outsourc','invest','licens','integrat','coordinat','synergiz','associat',
    'confedera','federa','union','unit','amalgamat','conglomerat','combin',
    'buyout','companion','concur','concert','comply','complement','assist',
    'takeover','accession','procure','suppl','conjoint','support','adjust',
    'adjunct','patronag','subsid','affiliat','endors'
]

# æ–‡æœ¬æ¸…ç†å‡½æ•°ï¼šå»é™¤éæ³•å­—ç¬¦ / Clean text
def clean_text(text):
    return ''.join(c for c in text if unicodedata.category(c)[0] != 'C' or c in ('\n','\t'))

# æå–å•ä¸ª Word æ–‡ä»¶ä¸­çš„å¥å­ / Extract sentences
def extract_sentences_from_docx(filepath):
    try:
        doc = Document(filepath)
    except Exception as e:
        print(f"â— æ— æ³•è¯»å–æ–‡ä»¶ {filepath}: {e}")
        return []

    collecting = False
    current_article = ''
    all_articles = []
    for para in doc.paragraphs:
        txt = para.text.strip()
        if not txt: continue
        if txt == 'Body':
            collecting = True
            current_article = ''
            continue
        if txt == 'Notes' and collecting:
            collecting = False
            all_articles.append(current_article.strip())
            continue
        if collecting:
            current_article += ' ' + txt

    sentences = []
    for article in all_articles:
        for sent in re.split(r'\.\s*', article):
            sent = sent.strip()
            if len(sent) < 5: continue
            sent = clean_text(sent)
            if sent:
                sentences.append(sent)
    return sentences

# éå†å¹¶å¤„ç† docx æ–‡ä»¶ï¼Œå…¼å®¹ 0/1/2 å±‚æ–‡ä»¶å¤¹
records = []
docx_files = []
for root, dirs, files in os.walk(ROOT_DIR):
    for fname in files:
        if not fname.endswith('.docx') or fname.startswith('~$'): continue
        path = os.path.join(root, fname)
        rel = os.path.relpath(path, ROOT_DIR).split(os.sep)
        if len(rel) >= 3:
            tier1, tier2, filename = rel[0], rel[1], rel[2]
        elif len(rel) == 2:
            tier1, tier2, filename = rel[0], '', rel[1]
        else:
            tier1, tier2, filename = '', '', rel[0]
        docx_files.append((path, tier1, tier2, filename))

for path, tier1, tier2, filename in tqdm(docx_files, desc="ğŸ“„ å¤„ç† Word æ–‡ä»¶", ncols=100):
    for sent in extract_sentences_from_docx(path):
        hits = [k for k in KEYWORD_ROOTS if k in sent.lower()]
        records.append({
            'Tier_1': tier1,
            'Tier_2': tier2,
            'Filename': filename,
            'Sentence': sent,
            'Hit_Count': len(hits),
            'Matched_Keywords': '; '.join(hits)
        })

# æ„å»º DataFrame å¹¶æ’åº
df = pd.DataFrame(records, columns=['Tier_1','Tier_2','Filename','Sentence','Hit_Count','Matched_Keywords'])
if not df.empty:
    df['Hit_Flag'] = df['Hit_Count'].apply(lambda x: 1 if x>0 else 0)
    df = df.sort_values(['Hit_Flag','Tier_1','Tier_2','Filename'], ascending=[False,True,True,True]).reset_index(drop=True)
    df = df.drop(columns=['Hit_Flag'])

# è¾“å‡ºä¸º CSV
if not df.empty:
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"âœ… å…¨éƒ¨å¤„ç†å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶ï¼š{OUTPUT_CSV}")
else:
    print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½• docx æ–‡ä»¶æˆ–å†…å®¹ä¸ºç©ºã€‚")
